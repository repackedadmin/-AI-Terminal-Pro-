ğŸ›¡ï¸ AI Terminal Pro ğŸ›¡ï¸

A privacy-first, terminal-based AI assistant you actually control. Run LLMs locally (via Ollama) or through self-hosted endpoints (like Hugging Face) â€” no cloud lock-in, no data collection, no nonsense.

Built for developers, power users, and privacy-first professionals.

ğŸ”‘ Features: ğŸ”‘

ğŸ’» Local or Self-Hosted Model Support (Ollama, Hugging Face)
ğŸ§  RAG-Enabled Context Memory (local vector database)
ğŸ› ï¸ Custom Tooling (Python, JSON, YAML)
ğŸ” No Telemetry or Tracking â€” Your data stays with you
ğŸ“ Session & Project Management with persistent memory
ğŸŒ Encrypted API Access for remote/mobile use
ğŸ”Œ MCP Server Integration (file systems, APIs, GitHub, databases)
ğŸ§ª Fine-Tuning + LoRA + RLHF for custom workflows
ğŸ¨ Modern Terminal UI (built with Textual)

âš™ï¸ Tech Stack âš™ï¸

Python Â· PyTorch Â· Transformers Â· SQLite Â· Flask Â· Textual Â· Cryptography

ğŸ‘¥ Contributing ğŸ‘¥ 

We welcome contributions! Whether it's fixing bugs, improving documentation, or adding new features â€” check out our CONTRIBUTING.md to get started.

ğŸ“œ License ğŸ“œ

This project is licensed under the MIT License â€” see LICENSE for details.

Use it. Modify it. Make it yours.

Your data. Your models. Your rules.
